{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interrogating local Gutenberg docs with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: [Talk to your Text files in Vector Databases with GPT-4 and ChromaDB](https://medium.com/@rubentak/unleashing-the-power-of-intelligent-chatbots-with-gpt-4-and-vector-databases-a-step-by-step-8027e2ce9e78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the basic parameters needed for Chroma, considering that the data already exists on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db2'\n",
    "\n",
    "# OpenAI embeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the persisted database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                   embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the data out of the database again, we need to create a retriever. This retriever will return all the documents (or chucks) related to the question asked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = vectordb.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Q&A chain\n",
    "The chain will be created. Consider it to be akin to the prompt in ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how our chatbot will come to the answers that it returns, we can create the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the previous query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The Will is the fundamental concept in many philosophical theories. It is typically described as an internal, conscious force that drives and motivates us to take certain actions or make certain decisions. The Will is often seen as separate from our emotions and desires, and is considered to be a higher power that guides us in our lives.\n",
      "\n",
      "\n",
      "Sources:\n",
      "D:\\src\\pareidolia\\gutenberg\\Thus Spake Zarathustra, by Friedrich Nietzsche.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Beyond Good and Evil, by Friedrich Nietzsche.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Thus Spake Zarathustra, by Friedrich Nietzsche.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Beyond Good and Evil, by Friedrich Nietzsche.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Will?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The Stoics held that material objects alone existed, in contrast to Plato's view that only Ideas or Prototypes of phenomena truly exist. The Stoics also believed in a spiritual force immanent in the material universe, while Plato did not.\n",
      "\n",
      "\n",
      "Sources:\n",
      "D:\\src\\pareidolia\\gutenberg\\Meditations, by Marcus Aurelius.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Meditations, by Marcus Aurelius.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Meditations, by Marcus Aurelius.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Meditations, by Marcus Aurelius.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"How did the stoics differ from Plato\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " A philosopher would argue that man's greatness and worth can be determined by the amount and variety of things he can bear and take responsibility for, and the extent to which he can stretch his responsibility.\n",
      "\n",
      "\n",
      "Sources:\n",
      "D:\\src\\pareidolia\\gutenberg\\Beyond Good and Evil, by Friedrich Nietzsche.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Beyond Good and Evil, by Friedrich Nietzsche.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Beyond Good and Evil, by Friedrich Nietzsche.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Beyond Good and Evil, by Friedrich Nietzsche.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"How can man be freed of the constraints of Ethics?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Nietzsche thought that the Stoics forced themselves to see nature falsely, and that their philosophy was a form of self-tyranny. He also noted that their system of physics was materialism with an infusion of pantheism, and that they believed that virtue was the highest good and the source of happiness.\n",
      "\n",
      "\n",
      "Sources:\n",
      "D:\\src\\pareidolia\\gutenberg\\Beyond Good and Evil, by Friedrich Nietzsche.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Meditations, by Marcus Aurelius.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Meditations, by Marcus Aurelius.txt\n",
      "D:\\src\\pareidolia\\gutenberg\\Meditations, by Marcus Aurelius.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What did Nietzche think of the stoics?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
